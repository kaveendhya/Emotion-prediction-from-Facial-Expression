Emotion Prediction using Facial Expressions


Emotion state prediction using facial expressions is one of the subcomponents to be addressed in 
this project, with applications ranging from improving human-computer interaction to assisting 
in mental health diagnosis. However, accurately predicting an individual's emotional state solely 
from facial expressions remains a difficult challenge. To address this, the study intends to 
develop a robust face emotion prediction model using deep learning techniques.
Another challenge that can be identified is enhancing accuracy by considering an individual's 
gender when predicting emotional states from facial expressions. The main key concern 
regarding Gender-Related Expression Variability is that individuals of different genders may 
exhibit variations in their facial expressions when experiencing the same emotion.
Hence, examining the impact of gender variations in Facial Expression Recognition (FER) 
training can lead to an improved understanding of the significance of specific facial regions. This 
knowledge can then be applied to the creation of improved models, ultimately affecting FERbased applications.
Moreover, deep learning models require high-quality and diverse datasets. However, research in 
this field often relies on existing datasets, which may not always have a balanced representation 
of gender. Hence, the challenge of finding separate datasets for males and females is a critical 
issue.


Objective:
Developed a predictive model which utilizes facial expressions to predict a individual's emotional 
state. The model should take a multimodal approach, taking into account the user's age and 
gender as extra considerations.
        • Developed a model to predict emotional state from facial expressions without considering 
        gender.
        • Developed separate models using gender-specific datasets for males and females.
        • Experiment with gender-based and general model development using two technologies.
        • Analyzing results do model comparison to identify the impact of gender for facial expression 
        recognition.
